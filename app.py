# app.py

import streamlit as st
from news_collector import fetch_news
from analyzer import analyze_article
from database import save_article, get_all_articles

st.set_page_config(page_title="ÙƒØ´Ù Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„ÙƒØ§Ø°Ø¨Ø© Ø­ÙˆÙ„ Ø³ÙˆØ±ÙŠØ§", layout="wide")

st.title("ğŸ•µï¸â€â™‚ï¸ Ù…Ù†ØµØ© ÙƒØ´Ù Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„ÙƒØ§Ø°Ø¨Ø© Ø­ÙˆÙ„ Ø³ÙˆØ±ÙŠØ§")
st.markdown("Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù†ØµØ© ØªØ¬Ù…Ø¹ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ÙˆØªÙØ­Ù„Ù„Ù‡Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„ØªØ­Ø¯ÙŠØ¯ Ù…Ø¯Ù‰ Ù…ÙˆØ«ÙˆÙ‚ÙŠØªÙ‡Ø§.")

# Ø²Ø± Ø¬Ù„Ø¨ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
if st.button("ğŸ” Ø¬Ù„Ø¨ ÙˆØªØ­Ù„ÙŠÙ„ Ø¢Ø®Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø±"):
    articles = fetch_news()
    with st.spinner("ÙŠØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±..."):
        for article in articles:
            title = article.get("title", "")
            content = article.get("content") or article.get("description", "")
            url = article.get("url", "")
            published_at = article.get("publishedAt", "")

            if title and content:
                analysis = analyze_article(title, content)
                save_article(title, content, url, analysis, published_at)

    st.success("âœ… ØªÙ… Ø¬Ù„Ø¨ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ù†Ø¬Ø§Ø­.")

st.markdown("---")
st.subheader("ğŸ“° Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø­Ù„Ù„Ø©:")

# Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©
rows = get_all_articles()
for row in rows:
    id, title, content, url, analysis, published_at = row

    with st.expander(f"ğŸ—ï¸ {title}"):
        st.write(f"**ØªØ§Ø±ÙŠØ® Ø§Ù„Ù†Ø´Ø±:** {published_at}")
        st.write(f"**Ø§Ù„Ø±Ø§Ø¨Ø·:** [Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…ØµØ¯Ø±]({url})")
        st.write(f"**Ø§Ù„Ù…Ø­ØªÙˆÙ‰:** {content}")
        st.markdown("---")
        st.write(f"**ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ:**")
        st.info(analysis)
